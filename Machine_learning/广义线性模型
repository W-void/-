为什么逻辑回归=线性回归+sigmoid；为什么多项式回归=线性回归+softmax
为什么我们对θTx做某种变换后就可以拟合各种目标函数h(x)
将sigmoid和softmax视为概率值到底准不准确，我们为什么不用其他的函数

这一切的答案就在GLM，广义线性模型里：
说GLM就绕不开指数分布族，
      p(y;η)=b(y)exp(ηT*T(y)−a(η))  
p表示概率，ηT表转置，和T(y)相乘后是一个实数，T(y)是充分统计量，一般是y，a,b不用管，就是单纯的函数。
高斯分布，伯努利分布等等都属于指数分布族。
为什么一定要让其他的分布经过复杂的变换，变成exp family呢？是因为ef被证明有很多我也听不懂的好处。
接下来要进入正题了，什么是GLM？
满足三个假设(也叫设计)的，就是GLM
(1)p(y|x;θ) ~ ExpFamily(η) 
(2)给定x,目标函数是输出T(y)的期望值，即h(x)=E[T(y)|x] 
(3)η=θTx,当η是实数时才有意义，否则是ηi=θTix。
应该是GLM的性质就是基于这三个设计推导的
一个很重要的性质就是η与x是线性的关系，也就意味着线性函数可以拟合更多的分布。

sigmoid和softmax都是GLM的h(x)
至于costfunction，再用极大似然估计估计p(y;η)，最小二乘法为什么用平法差而不用四次方八次方做cost，就是这样得出来的
